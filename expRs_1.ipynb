{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ray import tune\n",
    "\n",
    "from rayTune_common.configs import config5, config4, config3, config2, config1\n",
    "from rayTune_common.constants import ins, outs, metric, mode\n",
    "from rayTune_common.constants import rs_logdir_5, rs_logdir_4, rs_logdir_3, rs_logdir_2, rs_logdir_1\n",
    "from rayTune_common.model import Net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = \"dataset/training_set.csv\"\n",
    "train_set = pd.read_csv(path, index_col=0)\n",
    "path = \"dataset/validation_set.csv\"\n",
    "val_set = pd.read_csv(path, index_col=0)\n",
    "path = \"dataset/test_set.csv\"\n",
    "test_set = pd.read_csv(path, index_col=0)\n",
    "\n",
    "\n",
    "def prepare_data(\n",
    "        input_cols: [],\n",
    "        output_cols: [],\n",
    "        train_batch_size: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepares the dataset to be used for HPO\n",
    "    Converts to torch tensors and dataset loaders\n",
    "    :param input_cols: list of strings\n",
    "    :param output_cols: list of strings\n",
    "    :param train_batch_size: Batch size\n",
    "    :return:\n",
    "    :return: train_loader, x_val, y_val, val_loader, x_test, y_test\n",
    "    \"\"\"\n",
    "    # INPUT_COLS = ['CHK', 'PWH', 'PDC', 'TWH', 'FGAS', 'FOIL']\n",
    "    # OUTPUT_COLS = ['QTOT']\n",
    "\n",
    "    # Get input and output tensors and convert them to torch tensors\n",
    "    x_train = torch.from_numpy(train_set[input_cols].values).to(torch.float)\n",
    "    y_train = torch.from_numpy(train_set[output_cols].values).to(torch.float)\n",
    "\n",
    "    x_val = torch.from_numpy(val_set[input_cols].values).to(torch.float)\n",
    "    y_val = torch.from_numpy(val_set[output_cols].values).to(torch.float)\n",
    "\n",
    "    # Create dataset loaders\n",
    "    # Here we specify the batch size and if the dataset should be shuffled\n",
    "    train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=len(val_set), shuffle=False)\n",
    "\n",
    "    # Get input and output as torch tensors\n",
    "    x_test = torch.from_numpy(test_set[input_cols].values).to(torch.float)\n",
    "    y_test = torch.from_numpy(test_set[output_cols].values).to(torch.float)\n",
    "\n",
    "    return train_loader, x_val, y_val, val_loader, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(config, checkpoint_dir=None):\n",
    "    \"\"\"\n",
    "    :param config: hyperparameter configuration\n",
    "    :param checkpoint_dir: local checkpoint dir. Leave blank to use ~/ray_results\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net = Net(\n",
    "        len(ins),\n",
    "        int(config[\"hidden_layers\"]),\n",
    "        int(config[\"hidden_layer_width\"]),\n",
    "        len(outs),\n",
    "        dropout_value=config[\"dropout\"]\n",
    "    )\n",
    "\n",
    "    net = net.to(net.device)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = torch.nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    # The `checkpoint_dir` parameter gets passed by Ray Tune when a checkpoint\n",
    "    # should be restored.\n",
    "    if checkpoint_dir:\n",
    "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        model_state, optimizer_state = torch.load(checkpoint)\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    # Import training, validation and test data\n",
    "    train_loader, x_valid, y_valid, val_loader, x_test, y_test = prepare_data(\n",
    "        input_cols=ins,\n",
    "        output_cols=outs,\n",
    "        train_batch_size=64\n",
    "    )\n",
    "\n",
    "    # Train Network\n",
    "    for epoch in range(100):\n",
    "        # specify that we are in training mode\n",
    "        net.train()\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            inputs, labels = inputs.to(net.device), labels.to(net.device)\n",
    "            # Zero the parameter gradients (from last iteration)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Compute cost function\n",
    "            batch_mse = criterion(outputs, labels)\n",
    "\n",
    "            reg_loss = 0\n",
    "            for param in net.parameters():\n",
    "                reg_loss += param.pow(2).sum()\n",
    "\n",
    "            cost = batch_mse + config[\"l2\"] * reg_loss\n",
    "\n",
    "            # Backward propagation to compute gradient\n",
    "            cost.backward()\n",
    "\n",
    "            # Update parameters using gradient\n",
    "            optimizer.step()\n",
    "\n",
    "        # Specify that we are in evaluation mode\n",
    "        net.eval()\n",
    "\n",
    "        # Evaluate model on validation data\n",
    "        mse_val = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(net.device), labels.to(net.device)\n",
    "            mse_val += torch.sum(torch.pow(labels - net(inputs), 2)).item()\n",
    "        mse_val /= len(val_loader.dataset)\n",
    "\n",
    "        # Here we save a checkpoint. It is automatically registered with\n",
    "        # Ray Tune and will potentially be passed as the `checkpoint_dir`\n",
    "        # parameter in future iterations.\n",
    "        with tune.checkpoint_dir(step=epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save(\n",
    "                (net.state_dict(), optimizer.state_dict()), path)\n",
    "        tune.report(mean_square_error=mse_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def optimize(config: {}, iterations: int, experiment_name: str, logdir: str):\n",
    "    result = tune.run(\n",
    "        tune.with_parameters(train),\n",
    "        name=experiment_name,\n",
    "        config=config,\n",
    "        metric=metric,\n",
    "        mode=mode,\n",
    "        num_samples=iterations,\n",
    "        verbose=1,\n",
    "        checkpoint_score_attr=\"min-mean_square_error\",\n",
    "        keep_checkpoints_num=2,\n",
    "        local_dir=logdir,\n",
    "        resources_per_trial={\"cpu\": 1, \"gpu\": 0}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def experiment():\n",
    "    for i in range(0, 15):\n",
    "        print(\"Starting New Experiment\")\n",
    "        experiment_name = \"rs_\" + str(i).rjust(3, \"0\")\n",
    "        optimize(\n",
    "            config=config5,\n",
    "            iterations=100,\n",
    "            experiment_name=experiment_name,\n",
    "            logdir=rs_logdir_5\n",
    "        )\n",
    "\n",
    "        print(\"Starting New Experiment\")\n",
    "        experiment_name = \"rs_\" + str(i).rjust(3, \"0\")\n",
    "        optimize(\n",
    "            config=config4,\n",
    "            iterations=100,\n",
    "            experiment_name=experiment_name,\n",
    "            logdir=rs_logdir_4\n",
    "        )\n",
    "\n",
    "        print(\"Starting New Experiment\")\n",
    "        experiment_name = \"rs_\" + str(i).rjust(3, \"0\")\n",
    "        optimize(\n",
    "            config=config3,\n",
    "            iterations=100,\n",
    "            experiment_name=experiment_name,\n",
    "            logdir=rs_logdir_3\n",
    "        )\n",
    "\n",
    "        print(\"Starting New Experiment\")\n",
    "        experiment_name = \"rs_\" + str(i).rjust(3, \"0\")\n",
    "        optimize(\n",
    "            config=config2,\n",
    "            iterations=100,\n",
    "            experiment_name=experiment_name,\n",
    "            logdir=rs_logdir_2\n",
    "        )\n",
    "\n",
    "        print(\"Starting New Experiment\")\n",
    "        experiment_name = \"rs_\" + str(i).rjust(3, \"0\")\n",
    "        optimize(\n",
    "            config=config1,\n",
    "            iterations=100,\n",
    "            experiment_name=experiment_name,\n",
    "            logdir=rs_logdir_1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}