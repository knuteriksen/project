{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from ray.tune import Analysis\n",
    "\n",
    "from rayTune_common.constants import metric, mode\n",
    "from rayTune_common.test import test_model\n",
    "from rayTune_common.utils import config_to_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Analyse ray tune logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 0 -- /home/knut/Documents/project/run_results/run6/xp_000\n",
      "mse: 1.5655752420425415, trial: 26\n",
      "Experiment: 1 -- /home/knut/Documents/project/run_results/run6/xp_001\n",
      "mse: 2.4260880947113037, trial: 87\n",
      "Experiment: 2 -- /home/knut/Documents/project/run_results/run6/xp_002\n",
      "mse: 7.045718193054199, trial: 93\n",
      "Experiment: 3 -- /home/knut/Documents/project/run_results/run6/xp_003\n",
      "mse: 3.390287160873413, trial: 27\n",
      "Experiment: 4 -- /home/knut/Documents/project/run_results/run6/xp_004\n",
      "mse: 3.295583724975586, trial: 28\n",
      "Experiment: 5 -- /home/knut/Documents/project/run_results/run6/xp_005\n",
      "mse: 5.838708877563477, trial: 24\n",
      "Experiment: 6 -- /home/knut/Documents/project/run_results/run6/xp_006\n",
      "mse: 1.8179038763046265, trial: 89\n",
      "Experiment: 7 -- /home/knut/Documents/project/run_results/run6/xp_007\n",
      "mse: 2.953498125076294, trial: 15\n",
      "Experiment: 8 -- /home/knut/Documents/project/run_results/run6/xp_008\n",
      "mse: 3.4157166481018066, trial: 39\n",
      "Experiment: 9 -- /home/knut/Documents/project/run_results/run6/xp_009\n",
      "mse: 1.5211414098739624, trial: 55\n",
      "Experiment: 10 -- /home/knut/Documents/project/run_results/run6/xp_010\n",
      "mse: 1.2506372928619385, trial: 66\n",
      "Experiment: 11 -- /home/knut/Documents/project/run_results/run6/xp_011\n",
      "mse: 1.8450732231140137, trial: 61\n",
      "Experiment: 12 -- /home/knut/Documents/project/run_results/run6/xp_012\n",
      "mse: 2.9981603622436523, trial: 8\n",
      "Experiment: 13 -- /home/knut/Documents/project/run_results/run6/xp_013\n",
      "mse: 2.951615333557129, trial: 36\n",
      "Experiment: 14 -- /home/knut/Documents/project/run_results/run6/xp_014\n",
      "mse: 3.1574089527130127, trial: 100\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "path_to_run_results = \"/home/knut/Documents/project/run_results/run6\"\n",
    "path_to_csv = os.path.join(path_to_run_results, \"results.csv\")\n",
    "path_to_config_csv = os.path.join(path_to_run_results, \"config.csv\")\n",
    "\n",
    "list_experiments = [f.path for f in os.scandir(path_to_run_results) if f.is_dir()]\n",
    "list_experiments.sort(key=lambda x: x.split(\"_\")[-1])\n",
    "\n",
    "for experient_number, path_to_experiment in enumerate(list_experiments):\n",
    "    print(f\"Experiment: {experient_number} -- {path_to_experiment}\")\n",
    "    experiment_data = {}\n",
    "\n",
    "    best_trial_analysis = Analysis(path_to_experiment, default_metric=metric, default_mode=mode)\n",
    "    best_trial_config = best_trial_analysis.get_best_config(metric=metric, mode=mode)\n",
    "    best_trial_logdir = best_trial_analysis.get_best_logdir(metric=metric, mode=mode)\n",
    "    list_best_trial_checkpoints = [f.path for f in os.scandir(best_trial_logdir) if f.is_dir()]\n",
    "    list_best_trial_checkpoints.sort(key=lambda x: int(x.split(\"_\")[-1]))\n",
    "    best_trial_checkpoint_path = os.path.join(list_best_trial_checkpoints[-1], \"checkpoint\")\n",
    "    best_trial_model = config_to_model(config=best_trial_config, checkpoint_path=best_trial_checkpoint_path)\n",
    "    best_trial_mse = test_model(model=best_trial_model, batch_size=best_trial_config[\"batch_size\"])\n",
    "    print(f'mse: {best_trial_mse}, trial: {best_trial_logdir.split(\"_\")[4]}')\n",
    "\n",
    "    list_experiment_trials = [f.path for f in os.scandir(path_to_experiment) if f.is_dir()]\n",
    "    list_experiment_trials.sort(key=lambda x: int(x.split(\"_\")[4]))\n",
    "\n",
    "    for trial_number, path_to_trial in enumerate(list_experiment_trials):\n",
    "        list_trial_checkpoints = [f.path for f in os.scandir(path_to_trial) if f.is_dir()]\n",
    "        list_trial_checkpoints.sort(key=lambda x: int(x.split(\"_\")[-1]))\n",
    "\n",
    "        trial_checkpoint_path = os.path.join(list_trial_checkpoints[-1], \"checkpoint\")\n",
    "\n",
    "        trial_analysis = Analysis(path_to_trial, default_metric=metric, default_mode=mode)\n",
    "        trial_config = trial_analysis.get_best_config(metric=metric, mode=mode)\n",
    "\n",
    "        trial_model = config_to_model(config=trial_config, checkpoint_path=trial_checkpoint_path)\n",
    "\n",
    "        trial_mse = test_model(model=trial_model, batch_size=trial_config[\"batch_size\"])\n",
    "        experiment_data[trial_number] = trial_mse\n",
    "\n",
    "    sorted_experiment_data = dict(sorted(experiment_data.items()))\n",
    "    data.append(sorted_experiment_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Convert into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best trial based on test mse\n",
    "Store the config of the best model as csv file along with test mse and trial number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    batch_size  dropout  hidden_layer_width  hidden_layers          l2  \\\n",
      "0            4        0               100.0            7.0  0.00100000   \n",
      "1            8        0               120.0            8.0  0.00100000   \n",
      "2            8        0                80.0            5.0  0.00100000   \n",
      "3            4        0               100.0            5.0  0.04591141   \n",
      "4           64        0                40.0           10.0  0.04945592   \n",
      "5           64        0                60.0           10.0  0.04103043   \n",
      "6            4        0                70.0           10.0  0.07726434   \n",
      "7           64        0               120.0            2.0  0.00100000   \n",
      "8           32        0                70.0            7.0  0.09744227   \n",
      "9            4        0                70.0            6.0  0.01815962   \n",
      "10           4        0                70.0            3.0  0.00597970   \n",
      "11           4        0                90.0            4.0  0.00100000   \n",
      "12           4        0               110.0            7.0  0.05003437   \n",
      "13           8        0               120.0           10.0  0.00100000   \n",
      "14           4        0                30.0            6.0  0.00100000   \n",
      "\n",
      "            lr         mse  trial number  \n",
      "0   0.00055414  1.23493659            61  \n",
      "1   0.01981384  1.08851588            93  \n",
      "2   0.00065331  1.20578945            89  \n",
      "3   0.00019017  1.93369329            30  \n",
      "4   0.00123524  1.59831119            66  \n",
      "5   0.03587076  1.41644323            35  \n",
      "6   0.00118276  1.53580141            31  \n",
      "7   0.10000000  2.11713934            10  \n",
      "8   0.00310410  1.03260529            77  \n",
      "9   0.00035424  1.52114141            54  \n",
      "10  0.00334648  1.18982828            53  \n",
      "11  0.00119544  0.92035806            64  \n",
      "12  0.00041147  1.67585886            60  \n",
      "13  0.00017586  1.48811722            36  \n",
      "14  0.03021095  1.14589858            89  \n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "column_names = 1\n",
    "col_index_of_min = df.idxmin(axis=1)\n",
    "value_of_min = df.min(axis=1)\n",
    "for i in range(len(col_index_of_min)):\n",
    "    path = os.path.join(path_to_run_results, \"xp_\" + str(i).rjust(3, \"0\"))\n",
    "    list_experiment_trials = [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "    list_experiment_trials.sort(key=lambda x: int(x.split(\"_\")[4]))\n",
    "    path_to_best_test_mse = list_experiment_trials[col_index_of_min[i]]\n",
    "\n",
    "    list_trial_checkpoints = [f.path for f in os.scandir(path_to_best_test_mse) if f.is_dir()]\n",
    "    list_trial_checkpoints.sort(key=lambda x: int(x.split(\"_\")[-1]))\n",
    "    trial_checkpoint_path = os.path.join(list_trial_checkpoints[-1], \"checkpoint\")\n",
    "    trial_analysis = Analysis(path_to_best_test_mse, default_metric=metric, default_mode=mode)\n",
    "    trial_config = trial_analysis.get_best_config(metric=metric, mode=mode)\n",
    "    trial_model = config_to_model(config=trial_config, checkpoint_path=trial_checkpoint_path)\n",
    "    trial_mse = test_model(model=trial_model, batch_size=trial_config[\"batch_size\"])\n",
    "    assert (trial_mse == value_of_min[i])\n",
    "\n",
    "    trial_config[\"mse\"] = trial_mse\n",
    "    trial_config[\"trial number\"] = col_index_of_min[i]\n",
    "\n",
    "    data.append(trial_config)\n",
    "\n",
    "config_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add mean and variance to test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"best\"] = df.min(axis=1)\n",
    "df.loc[\"mean\"] = df.mean(axis=0)\n",
    "df.loc[\"var\"] = df.var(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store dataframes as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_to_csv)\n",
    "config_df.to_csv(path_to_config_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}